#!/usr/bin/env python3
"""
ë³‘ë ¬ ë°ì´í„° ìˆ˜ì§‘ ì‹œìŠ¤í…œ
4ê°œì˜ ì›Œì»¤ê°€ ë™ì‹œì— PDF ë‹¤ìš´ë¡œë“œ + ë°ì´í„° ì¶”ì¶œ
ì™„ì „ headless ëª¨ë“œë¡œ í™”ë©´ ë°©í•´ ì—†ìŒ
ìë™ í ì¬ì¶©ì „ ê¸°ëŠ¥ í¬í•¨
"""

import multiprocessing as mp
from multiprocessing import Queue, Process, Manager
import time
from pathlib import Path
import logging
from datetime import datetime
import sys
import subprocess

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ì¶”ê°€
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from scripts.pdf_data_extractor import PDFDataExtractor

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - [Worker-%(process)d] - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


class ParallelCollector:
    """ë³‘ë ¬ ë°ì´í„° ìˆ˜ì§‘ê¸°"""
    
    def __init__(self, num_workers: int = 4):
        self.num_workers = num_workers
        self.project_root = Path(__file__).parent.parent
        self.queue_file = self.project_root / "data" / "papers_queue.txt"
        self.pdf_dir = self.project_root / "pdf" / "downloaded"
        self.results_dir = self.project_root / "data"
        
    def load_queue(self):
        """íì—ì„œ DOI ë¡œë“œ"""
        if not self.queue_file.exists():
            return []
        
        lines = self.queue_file.read_text().strip().split('\n')
        dois = [line.strip() for line in lines 
                if line.strip() and not line.startswith('#')]
        
        return dois
    
    def worker(self, worker_id: int, task_queue: Queue, result_queue: Queue):
        """
        ì›Œì»¤ í”„ë¡œì„¸ìŠ¤
        
        Args:
            worker_id: ì›Œì»¤ ID
            task_queue: ì‘ì—… í (DOI ì…ë ¥)
            result_queue: ê²°ê³¼ í (ì„±ê³µ/ì‹¤íŒ¨ ì¶œë ¥)
        """
        logger.info(f"ğŸš€ ì›Œì»¤ {worker_id} ì‹œì‘")
        
        # ê° ì›Œì»¤ë§ˆë‹¤ ë³„ë„ì˜ PDF ë””ë ‰í† ë¦¬
        worker_pdf_dir = self.pdf_dir / f"worker_{worker_id}"
        worker_pdf_dir.mkdir(exist_ok=True, parents=True)
        
        # PDF ì¶”ì¶œê¸° ì´ˆê¸°í™” (Selenium headless)
        try:
            extractor = PDFDataExtractor(worker_pdf_dir, use_selenium=True)
            logger.info(f"âœ… ì›Œì»¤ {worker_id}: PDF ì¶”ì¶œê¸° ì´ˆê¸°í™” ì™„ë£Œ")
        except Exception as e:
            logger.error(f"âŒ ì›Œì»¤ {worker_id}: ì´ˆê¸°í™” ì‹¤íŒ¨ - {str(e)}")
            return
        
        processed = 0
        
        while True:
            try:
                # íì—ì„œ DOI ê°€ì ¸ì˜¤ê¸° (íƒ€ì„ì•„ì›ƒ 5ì´ˆ)
                doi = task_queue.get(timeout=5)
                
                if doi is None:  # ì¢…ë£Œ ì‹ í˜¸
                    logger.info(f"ğŸ›‘ ì›Œì»¤ {worker_id} ì¢…ë£Œ (ì²˜ë¦¬: {processed}ê°œ)")
                    break
                
                logger.info(f"ğŸ“¥ ì›Œì»¤ {worker_id}: {doi} ì²˜ë¦¬ ì‹œì‘")
                
                # PDF ë‹¤ìš´ë¡œë“œ + ë°ì´í„° ì¶”ì¶œ
                paper_id = f"W{worker_id}_P{processed+1:03d}"
                
                try:
                    data = extractor.extract_all_data(doi, paper_id)
                    
                    if data:
                        logger.info(f"âœ… ì›Œì»¤ {worker_id}: {doi} ì„±ê³µ")
                        result_queue.put({
                            'worker_id': worker_id,
                            'doi': doi,
                            'status': 'success',
                            'data': data
                        })
                    else:
                        logger.warning(f"âš ï¸ ì›Œì»¤ {worker_id}: {doi} ë°ì´í„° ì—†ìŒ")
                        result_queue.put({
                            'worker_id': worker_id,
                            'doi': doi,
                            'status': 'no_data',
                            'data': None
                        })
                    
                    processed += 1
                    
                except Exception as e:
                    logger.error(f"âŒ ì›Œì»¤ {worker_id}: {doi} ì‹¤íŒ¨ - {str(e)}")
                    result_queue.put({
                        'worker_id': worker_id,
                        'doi': doi,
                        'status': 'error',
                        'error': str(e)
                    })
                
            except Queue.Empty:
                # íê°€ ë¹„ì–´ìˆìŒ - ë” ê¸°ë‹¤ë¦¼
                continue
            except KeyboardInterrupt:
                logger.info(f"âš ï¸ ì›Œì»¤ {worker_id} ì¤‘ë‹¨ë¨")
                break
            except Exception as e:
                logger.error(f"âŒ ì›Œì»¤ {worker_id} ì˜¤ë¥˜: {str(e)}")
                break
        
        # ì •ë¦¬
        try:
            extractor.cleanup()
        except:
            pass
    
    def run(self):
        """ë³‘ë ¬ ìˆ˜ì§‘ ì‹¤í–‰"""
        print("=" * 80)
        print("ğŸš€ ë³‘ë ¬ ë°ì´í„° ìˆ˜ì§‘ ì‹œìŠ¤í…œ")
        print("=" * 80)
        
        # DOI í ë¡œë“œ
        dois = self.load_queue()
        
        if not dois:
            print("âŒ íì— DOIê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        print(f"ğŸ“ í: {len(dois)}ê°œ DOI")
        print(f"ğŸ‘· ì›Œì»¤: {self.num_workers}ê°œ")
        print(f"â±ï¸  ì˜ˆìƒ ì‹œê°„: {len(dois) / self.num_workers * 2:.0f}ë¶„")
        print("=" * 80)
        
        # ë©€í‹°í”„ë¡œì„¸ì‹± í
        manager = Manager()
        task_queue = manager.Queue()
        result_queue = manager.Queue()
        
        # DOIë¥¼ ì‘ì—… íì— ì¶”ê°€
        for doi in dois:
            task_queue.put(doi)
        
        # ì¢…ë£Œ ì‹ í˜¸ ì¶”ê°€ (ì›Œì»¤ ìˆ˜ë§Œí¼)
        for _ in range(self.num_workers):
            task_queue.put(None)
        
        # ì›Œì»¤ í”„ë¡œì„¸ìŠ¤ ì‹œì‘
        workers = []
        for i in range(self.num_workers):
            p = Process(
                target=self.worker,
                args=(i+1, task_queue, result_queue)
            )
            p.start()
            workers.append(p)
        
        # ê²°ê³¼ ìˆ˜ì§‘
        results = {
            'success': [],
            'no_data': [],
            'error': []
        }
        
        start_time = time.time()
        
        # ì§„í–‰ ìƒí™© ëª¨ë‹ˆí„°ë§
        while any(w.is_alive() for w in workers):
            # ê²°ê³¼ íì—ì„œ ê°€ì ¸ì˜¤ê¸°
            while not result_queue.empty():
                result = result_queue.get()
                status = result['status']
                results[status].append(result)
                
                # ì§„í–‰ ìƒí™© ì¶œë ¥
                total_processed = sum(len(v) for v in results.values())
                elapsed = time.time() - start_time
                rate = total_processed / elapsed if elapsed > 0 else 0
                
                print(f"\rğŸ“Š ì§„í–‰: {total_processed}/{len(dois)} "
                      f"(ì„±ê³µ: {len(results['success'])}, "
                      f"ë°ì´í„°ì—†ìŒ: {len(results['no_data'])}, "
                      f"ì‹¤íŒ¨: {len(results['error'])}) "
                      f"| ì†ë„: {rate:.2f}ê°œ/ë¶„", end='')
            
            time.sleep(1)
        
        # ëª¨ë“  ì›Œì»¤ ì¢…ë£Œ ëŒ€ê¸°
        for w in workers:
            w.join()
        
        # ë‚¨ì€ ê²°ê³¼ ìˆ˜ì§‘
        while not result_queue.empty():
            result = result_queue.get()
            results[result['status']].append(result)
        
        # ìµœì¢… ê²°ê³¼
        print(f"\n\n{'=' * 80}")
        print("âœ… ìˆ˜ì§‘ ì™„ë£Œ!")
        print("=" * 80)
        print(f"ğŸ“Š ì´ ì²˜ë¦¬: {len(dois)}ê°œ")
        print(f"   âœ… ì„±ê³µ: {len(results['success'])}ê°œ")
        print(f"   âš ï¸ ë°ì´í„° ì—†ìŒ: {len(results['no_data'])}ê°œ")
        print(f"   âŒ ì‹¤íŒ¨: {len(results['error'])}ê°œ")
        print(f"â±ï¸  ì†Œìš” ì‹œê°„: {(time.time() - start_time)/60:.1f}ë¶„")
        print("=" * 80)
        
        # ë°ì´í„° ì €ì¥
        if results['success']:
            self.save_results(results['success'])
    
    
    def auto_refill_queue(self, min_dois: int = 10):
        """
        íê°€ ë¶€ì¡±í•˜ë©´ ìë™ìœ¼ë¡œ ìƒˆ DOI ê²€ìƒ‰
        
        Args:
            min_dois: ìµœì†Œ í•„ìš” DOI ê°œìˆ˜
        
        Returns:
            bool: ì„±ê³µ ì—¬ë¶€
        """
        logger.info(f"ğŸ” ìë™ DOI ê²€ìƒ‰ ì‹œì‘...")
        print("\n" + "=" * 80)
        print("ğŸ” íê°€ ë¶€ì¡±í•©ë‹ˆë‹¤. ìƒˆ DOI ìë™ ê²€ìƒ‰ ì¤‘...")
        print("=" * 80)
        
        try:
            # auto_doi_search.py ì‹¤í–‰
            auto_search_script = self.project_root / "scripts" / "auto_doi_search.py"
            
            if not auto_search_script.exists():
                logger.error("âŒ auto_doi_search.py íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                return False
            
            # Python ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰
            result = subprocess.run(
                [sys.executable, str(auto_search_script)],
                cwd=str(self.project_root),
                capture_output=True,
                text=True,
                timeout=120  # 2ë¶„ íƒ€ì„ì•„ì›ƒ
            )
            
            if result.returncode == 0:
                logger.info("âœ… ìƒˆ DOI ê²€ìƒ‰ ì™„ë£Œ")
                print("\nâœ… ìƒˆ DOIê°€ íì— ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤!")
                
                # ìƒˆë¡œ ì¶”ê°€ëœ DOI ê°œìˆ˜ í™•ì¸
                new_dois = self.load_queue()
                print(f"ğŸ“‹ í˜„ì¬ í: {len(new_dois)}ê°œ DOI")
                return True
            else:
                logger.error(f"âŒ DOI ê²€ìƒ‰ ì‹¤íŒ¨: {result.stderr}")
                return False
                
        except subprocess.TimeoutExpired:
            logger.error("âŒ DOI ê²€ìƒ‰ íƒ€ì„ì•„ì›ƒ (2ë¶„ ì´ˆê³¼)")
            return False
        except Exception as e:
            logger.error(f"âŒ DOI ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            return False
    
    
    def run_continuous(self, batch_size: int = 20, max_batches: int = None):
        """
        ë¬´í•œ ë³‘ë ¬ ìˆ˜ì§‘ (ìë™ í ì¬ì¶©ì „)
        
        Args:
            batch_size: ë°°ì¹˜ë‹¹ ì²˜ë¦¬í•  DOI ê°œìˆ˜
            max_batches: ìµœëŒ€ ë°°ì¹˜ ìˆ˜ (Noneì´ë©´ ë¬´í•œ)
        """
        print("=" * 80)
        print("ğŸš€ ë¬´í•œ ë³‘ë ¬ ë°ì´í„° ìˆ˜ì§‘ ì‹œìŠ¤í…œ (ìë™ í ì¬ì¶©ì „)")
        print("=" * 80)
        print(f"ğŸ“¦ ë°°ì¹˜ í¬ê¸°: {batch_size}ê°œ")
        print(f"ğŸ‘· ì›Œì»¤: {self.num_workers}ê°œ")
        if max_batches:
            print(f"ğŸ”¢ ìµœëŒ€ ë°°ì¹˜: {max_batches}ê°œ")
        else:
            print(f"â™¾ï¸  ë¬´í•œ ë°˜ë³µ (Ctrl+Cë¡œ ì¤‘ë‹¨)")
        print("=" * 80)
        
        batch_count = 0
        total_collected = 0
        
        try:
            while True:
                batch_count += 1
                
                print(f"\n{'='*80}")
                print(f"ğŸ“¦ ë°°ì¹˜ #{batch_count} ì‹œì‘")
                print("="*80)
                
                # 1. í í™•ì¸
                dois = self.load_queue()
                
                # 2. íê°€ ë¶€ì¡±í•˜ë©´ ìë™ ì¬ì¶©ì „
                if not dois or len(dois) < 10:
                    print(f"âš ï¸ í ë¶€ì¡± (í˜„ì¬: {len(dois)}ê°œ)")
                    
                    # ìë™ DOI ê²€ìƒ‰
                    if self.auto_refill_queue():
                        dois = self.load_queue()
                    else:
                        print("âŒ ìƒˆ DOI ê²€ìƒ‰ ì‹¤íŒ¨")
                
                # 3. ì—¬ì „íˆ ë¹„ì—ˆìœ¼ë©´ ì¢…ë£Œ
                if not dois:
                    print("\n" + "="*80)
                    print("âœ… ëª¨ë“  ë…¼ë¬¸ ìˆ˜ì§‘ ì™„ë£Œ!")
                    print(f"ğŸ“Š ì´ ë°°ì¹˜: {batch_count-1}ê°œ")
                    print(f"ğŸ“š ì´ ìˆ˜ì§‘: {total_collected}ê°œ")
                    print("="*80)
                    break
                
                # 4. ë°°ì¹˜ í¬ê¸°ë§Œí¼ë§Œ ì²˜ë¦¬
                batch_dois = dois[:batch_size]
                print(f"ğŸ“ ì´ë²ˆ ë°°ì¹˜: {len(batch_dois)}ê°œ DOI ì²˜ë¦¬")
                
                # 5. ë³‘ë ¬ ìˆ˜ì§‘ ì‹¤í–‰
                self.run_batch(batch_dois)
                total_collected += len(batch_dois)
                
                # 6. ì²˜ë¦¬ëœ DOIëŠ” íì—ì„œ ì œê±°
                self.remove_processed_dois(batch_dois)
                
                # 7. ìµœëŒ€ ë°°ì¹˜ ìˆ˜ í™•ì¸
                if max_batches and batch_count >= max_batches:
                    print(f"\nâœ… ìµœëŒ€ ë°°ì¹˜ ìˆ˜({max_batches})ì— ë„ë‹¬í–ˆìŠµë‹ˆë‹¤.")
                    break
                
                # 8. ë‹¤ìŒ ë°°ì¹˜ ì „ ëŒ€ê¸°
                print(f"\nâ¸ï¸  5ì´ˆ í›„ ë‹¤ìŒ ë°°ì¹˜ ì‹œì‘...")
                time.sleep(5)
                
        except KeyboardInterrupt:
            print("\n\nâš ï¸ ì‚¬ìš©ìê°€ ì¤‘ë‹¨í–ˆìŠµë‹ˆë‹¤.")
            print(f"ğŸ“Š ì´ ë°°ì¹˜: {batch_count}ê°œ")
            print(f"ğŸ“š ì´ ìˆ˜ì§‘: {total_collected}ê°œ")
    
    
    def run_batch(self, dois: list):
        """ë°°ì¹˜ ì²˜ë¦¬ (run() ë©”ì„œë“œ ë¶„ë¦¬)"""
        print(f"â±ï¸  ì˜ˆìƒ ì‹œê°„: {len(dois) / self.num_workers * 2:.0f}ë¶„")
        
        # ë©€í‹°í”„ë¡œì„¸ì‹± í
        manager = Manager()
        task_queue = manager.Queue()
        result_queue = manager.Queue()
        
        # DOIë¥¼ ì‘ì—… íì— ì¶”ê°€
        for doi in dois:
            task_queue.put(doi)
        
        # ì¢…ë£Œ ì‹ í˜¸ ì¶”ê°€
        for _ in range(self.num_workers):
            task_queue.put(None)
        
        # ì›Œì»¤ í”„ë¡œì„¸ìŠ¤ ì‹œì‘
        workers = []
        for i in range(self.num_workers):
            p = Process(
                target=self.worker,
                args=(i+1, task_queue, result_queue)
            )
            p.start()
            workers.append(p)
        
        # ê²°ê³¼ ìˆ˜ì§‘
        results = {
            'success': [],
            'no_data': [],
            'error': []
        }
        
        start_time = time.time()
        
        # ì§„í–‰ ìƒí™© ëª¨ë‹ˆí„°ë§
        while any(w.is_alive() for w in workers):
            while not result_queue.empty():
                result = result_queue.get()
                status = result['status']
                results[status].append(result)
                
                total_processed = sum(len(v) for v in results.values())
                elapsed = time.time() - start_time
                rate = total_processed / elapsed if elapsed > 0 else 0
                
                print(f"\rğŸ“Š ì§„í–‰: {total_processed}/{len(dois)} "
                      f"(ì„±ê³µ: {len(results['success'])}, "
                      f"ë°ì´í„°ì—†ìŒ: {len(results['no_data'])}, "
                      f"ì‹¤íŒ¨: {len(results['error'])}) "
                      f"| ì†ë„: {rate:.2f}ê°œ/ë¶„", end='')
            
            time.sleep(1)
        
        # ëª¨ë“  ì›Œì»¤ ì¢…ë£Œ ëŒ€ê¸°
        for w in workers:
            w.join()
        
        # ë‚¨ì€ ê²°ê³¼ ìˆ˜ì§‘
        while not result_queue.empty():
            result = result_queue.get()
            results[result['status']].append(result)
        
        print(f"\n\n{'=' * 80}")
        print("âœ… ë°°ì¹˜ ì™„ë£Œ!")
        print(f"   âœ… ì„±ê³µ: {len(results['success'])}ê°œ")
        print(f"   âš ï¸ ë°ì´í„° ì—†ìŒ: {len(results['no_data'])}ê°œ")
        print(f"   âŒ ì‹¤íŒ¨: {len(results['error'])}ê°œ")
        print(f"â±ï¸  ì†Œìš” ì‹œê°„: {(time.time() - start_time)/60:.1f}ë¶„")
        
        # ë°ì´í„° ì €ì¥
        if results['success']:
            self.save_results(results['success'])
    
    
    def remove_processed_dois(self, processed_dois: list):
        """
        ì²˜ë¦¬ëœ DOIë¥¼ íì—ì„œ ì œê±°
        
        Args:
            processed_dois: ì²˜ë¦¬ ì™„ë£Œëœ DOI ë¦¬ìŠ¤íŠ¸
        """
        if not self.queue_file.exists():
            return
        
        # ê¸°ì¡´ í ì½ê¸°
        lines = self.queue_file.read_text().strip().split('\n')
        
        # ì£¼ì„ê³¼ ë¹ˆ ì¤„ ìœ ì§€, ì²˜ë¦¬ëœ DOIë§Œ ì œê±°
        new_lines = []
        processed_set = set(processed_dois)
        
        for line in lines:
            line = line.strip()
            if not line or line.startswith('#'):
                new_lines.append(line)
            elif line not in processed_set:
                new_lines.append(line)
        
        # í íŒŒì¼ ì—…ë°ì´íŠ¸
        self.queue_file.write_text('\n'.join(new_lines) + '\n')
        logger.info(f"ğŸ—‘ï¸ {len(processed_dois)}ê°œ DOIë¥¼ íì—ì„œ ì œê±°")


    def save_results(self, success_results):
        """ê²°ê³¼ë¥¼ CSVë¡œ ì €ì¥"""
        import pandas as pd
        
        data_list = []
        for result in success_results:
            data_list.append(result['data'])
        
        df = pd.DataFrame(data_list)
        output_file = self.results_dir / f"parallel_collected_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv"
        df.to_csv(output_file, index=False)
        
        logger.info(f"ğŸ’¾ ê²°ê³¼ ì €ì¥: {output_file}")


def show_menu():
    """ëŒ€í™”í˜• ë©”ë‰´ í‘œì‹œ"""
    print("\n" + "="*80)
    print("ğŸš€ CsPbCl3 ë°ì´í„° ë§ˆì´ë‹ ìë™í™” ì‹œìŠ¤í…œ")
    print("="*80)
    print("\nğŸ“Š í˜„ì¬ ìƒíƒœ:")
    
    # í ìƒíƒœ
    queue_file = Path(__file__).parent.parent / "data" / "papers_queue.txt"
    if queue_file.exists():
        lines = queue_file.read_text().strip().split('\n')
        dois = [line.strip() for line in lines if line.strip() and not line.startswith('#')]
        print(f"   ğŸ“‹ ëŒ€ê¸° ì¤‘ì¸ ë…¼ë¬¸: {len(dois)}ê°œ")
    else:
        print(f"   âš ï¸  í íŒŒì¼ ì—†ìŒ")
    
    # ìˆ˜ì§‘ íŒŒì¼ ìƒíƒœ
    data_dir = Path(__file__).parent.parent / "data"
    collected_files = list(data_dir.glob("parallel_collected_*.csv"))
    if collected_files:
        print(f"   âœ… ìˆ˜ì§‘ ì™„ë£Œ ë°°ì¹˜: {len(collected_files)}ê°œ")
    
    # ì°¸ê³  ë°ì´í„°
    ref_file = data_dir / "reference_dataset.xlsx"
    if ref_file.exists():
        print(f"   ğŸ“š ì°¸ê³  ë°ì´í„°: 101 ìƒ˜í”Œ")
    
    print("\n" + "-"*80)
    print("\nì–´ë–¤ ì‘ì—…ì„ ìˆ˜í–‰í• ê¹Œìš”?\n")
    print("   1ï¸âƒ£  ë³‘ë ¬ ë°ì´í„° ìˆ˜ì§‘ (1íšŒ, í ì†Œì§„ ì‹œ ì¢…ë£Œ)")
    print("   2ï¸âƒ£  ë¬´í•œ ë°ì´í„° ìˆ˜ì§‘ (ìë™ í ì¬ì¶©ì „) ğŸ”¥")
    print("   3ï¸âƒ£  ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œ")
    print("   4ï¸âƒ£  ì›¹ ëŒ€ì‹œë³´ë“œ ì—´ê¸° (ë¸Œë¼ìš°ì €)")
    print("   5ï¸âƒ£  ìˆ˜ì§‘ ê²°ê³¼ í™•ì¸")
    print("   6ï¸âƒ£  DOI í ê´€ë¦¬")
    print("   0ï¸âƒ£  ì¢…ë£Œ")
    print("\n" + "-"*80)
    
    try:
        choice = input("\nğŸ‘‰ ì„ íƒ: ").strip()
        return choice
    except (KeyboardInterrupt, EOFError):
        print("\n\nğŸ‘‹ ì¢…ë£Œí•©ë‹ˆë‹¤.")
        sys.exit(0)


def handle_choice(choice: str):
    """ë©”ë‰´ ì„ íƒ ì²˜ë¦¬"""
    import subprocess
    import os
    
    project_root = Path(__file__).parent.parent
    
    if choice == "1":
        print("\nğŸš€ ë³‘ë ¬ ë°ì´í„° ìˆ˜ì§‘ì„ ì‹œì‘í•©ë‹ˆë‹¤ (1íšŒ)...\n")
        num_workers = min(4, mp.cpu_count())
        collector = ParallelCollector(num_workers=num_workers)
        collector.run()
    
    elif choice == "2":
        print("\nğŸ”¥ ë¬´í•œ ë°ì´í„° ìˆ˜ì§‘ì„ ì‹œì‘í•©ë‹ˆë‹¤ (ìë™ í ì¬ì¶©ì „)...\n")
        print("ğŸ’¡ íê°€ ë¶€ì¡±í•˜ë©´ ìë™ìœ¼ë¡œ ìƒˆ DOIë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤.")
        print("â¸ï¸  Ctrl+Cë¡œ ì¤‘ë‹¨ ê°€ëŠ¥\n")
        
        num_workers = min(4, mp.cpu_count())
        collector = ParallelCollector(num_workers=num_workers)
        
        # ë°°ì¹˜ í¬ê¸° ì„¤ì •
        try:
            batch_size = input("ğŸ“¦ ë°°ì¹˜ í¬ê¸° (ê¸°ë³¸ 20ê°œ, Enter=ê¸°ë³¸ê°’): ").strip()
            batch_size = int(batch_size) if batch_size else 20
        except:
            batch_size = 20
        
        # ìµœëŒ€ ë°°ì¹˜ ìˆ˜ ì„¤ì •
        try:
            max_batches = input("ğŸ”¢ ìµœëŒ€ ë°°ì¹˜ ìˆ˜ (Enter=ë¬´í•œ): ").strip()
            max_batches = int(max_batches) if max_batches else None
        except:
            max_batches = None
        
        collector.run_continuous(batch_size=batch_size, max_batches=max_batches)
        
    elif choice == "3":
        print("\nğŸ“Š ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...")
        print("   (Ctrl+Cë¡œ ì¢…ë£Œ)\n")
        time.sleep(1)
        
        # Python ì‹¤í–‰ íŒŒì¼ ê²½ë¡œ (venv í™œìš©)
        python_exe = sys.executable
        monitor_script = project_root / "scripts" / "monitor_dashboard.py"
        
        if monitor_script.exists():
            subprocess.run([python_exe, str(monitor_script)])
        else:
            print("âŒ monitor_dashboard.py íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    
    elif choice == "4":
        print("\nğŸŒ ì›¹ ëŒ€ì‹œë³´ë“œë¥¼ ìƒì„±í•©ë‹ˆë‹¤...\n")
        
        # ì›¹ ëŒ€ì‹œë³´ë“œ HTML ìƒì„±
        html_file = project_root / "dashboard.html"
        create_web_dashboard(html_file)
        
        print(f"âœ… ëŒ€ì‹œë³´ë“œ ìƒì„±: {html_file}")
        print("ğŸŒ VS Code Simple Browserì—ì„œ ìë™ìœ¼ë¡œ ì—´ê¸°...\n")
        
        # íŒŒì¼ URI ìƒì„±
        file_uri = html_file.as_uri()
        
        # open_simple_browser ë„êµ¬ ì‚¬ìš© ì•ˆë‚´
        print(f"ï¿½ ìƒì„±ëœ íŒŒì¼: {html_file}")
        print(f"ğŸ“ URL: {file_uri}\n")
        
        # ì‚¬ìš©ìì—ê²Œ URL ì œê³µ
        print("=" * 80)
        print("ğŸ’¡ ì•„ë˜ URLì„ ë³µì‚¬í•´ì„œ ë¸Œë¼ìš°ì €ì— ë¶™ì—¬ë„£ìœ¼ì„¸ìš”:")
        print(f"   {file_uri}")
        print("=" * 80)
    
    elif choice == "4":
        print("\nğŸ“Š ìˆ˜ì§‘ ê²°ê³¼ë¥¼ í™•ì¸í•©ë‹ˆë‹¤...\n")
        show_collection_results()
    
    elif choice == "5":
        print("\nğŸ“‹ DOI í ê´€ë¦¬...\n")
        manage_queue()
    
    elif choice == "0":
        print("\nğŸ‘‹ í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.\n")
        sys.exit(0)
    
    else:
        print("\nâŒ ì˜ëª»ëœ ì„ íƒì…ë‹ˆë‹¤. ë‹¤ì‹œ ì„ íƒí•´ì£¼ì„¸ìš”.")


def create_web_dashboard(output_file: Path):
    """ì›¹ ëŒ€ì‹œë³´ë“œ HTML ìƒì„±"""
    import pandas as pd
    
    project_root = Path(__file__).parent.parent
    data_dir = project_root / "data"
    
    # ë°ì´í„° ìˆ˜ì§‘
    collected_files = sorted(data_dir.glob("parallel_collected_*.csv"), reverse=True)
    
    total_papers = 0
    total_pdf = 0
    total_data = 0
    batch_info = []
    
    for file in collected_files[:5]:  # ìµœê·¼ 5ê°œ
        try:
            df = pd.read_csv(file)
            has_pdf = sum(df.get('Cl_source', pd.Series()).notna())
            has_data = sum(df.get('size_nm', pd.Series()).notna())
            
            total_papers += len(df)
            total_pdf += has_pdf
            total_data += has_data
            
            batch_info.append({
                'file': file.name,
                'papers': len(df),
                'pdf': has_pdf,
                'data': has_data
            })
        except:
            pass
    
    # HTML ìƒì„±
    html_content = f"""
<!DOCTYPE html>
<html lang="ko">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>CsPbCl3 ë°ì´í„° ë§ˆì´ë‹ ëŒ€ì‹œë³´ë“œ</title>
    <style>
        * {{ margin: 0; padding: 0; box-sizing: border-box; }}
        body {{
            font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, sans-serif;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            padding: 20px;
            color: #333;
        }}
        .container {{
            max-width: 1200px;
            margin: 0 auto;
            background: white;
            border-radius: 20px;
            padding: 40px;
            box-shadow: 0 20px 60px rgba(0,0,0,0.3);
        }}
        h1 {{
            color: #667eea;
            margin-bottom: 10px;
            font-size: 2.5em;
        }}
        .subtitle {{
            color: #999;
            margin-bottom: 30px;
            font-size: 1.1em;
        }}
        .stats {{
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(250px, 1fr));
            gap: 20px;
            margin-bottom: 40px;
        }}
        .stat-card {{
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            padding: 30px;
            border-radius: 15px;
            box-shadow: 0 10px 30px rgba(102, 126, 234, 0.3);
        }}
        .stat-value {{
            font-size: 3em;
            font-weight: bold;
            margin-bottom: 10px;
        }}
        .stat-label {{
            font-size: 1.2em;
            opacity: 0.9;
        }}
        .batch-table {{
            width: 100%;
            border-collapse: collapse;
            margin-top: 20px;
        }}
        .batch-table th {{
            background: #667eea;
            color: white;
            padding: 15px;
            text-align: left;
        }}
        .batch-table td {{
            padding: 15px;
            border-bottom: 1px solid #eee;
        }}
        .batch-table tr:hover {{
            background: #f8f9ff;
        }}
        .progress-bar {{
            width: 100%;
            height: 30px;
            background: #eee;
            border-radius: 15px;
            overflow: hidden;
            margin: 20px 0;
        }}
        .progress-fill {{
            height: 100%;
            background: linear-gradient(90deg, #667eea 0%, #764ba2 100%);
            display: flex;
            align-items: center;
            justify-content: center;
            color: white;
            font-weight: bold;
        }}
        .section {{
            margin-top: 40px;
        }}
        .section-title {{
            font-size: 1.8em;
            color: #667eea;
            margin-bottom: 20px;
            border-bottom: 3px solid #667eea;
            padding-bottom: 10px;
        }}
    </style>
</head>
<body>
    <div class="container">
        <h1>ğŸš€ CsPbCl3 ë°ì´í„° ë§ˆì´ë‹ ëŒ€ì‹œë³´ë“œ</h1>
        <div class="subtitle">ìë™í™”ëœ ë¬¸í—Œ ë°ì´í„° ìˆ˜ì§‘ ì‹œìŠ¤í…œ</div>
        
        <div class="stats">
            <div class="stat-card">
                <div class="stat-value">{total_papers}</div>
                <div class="stat-label">ì´ ë…¼ë¬¸ ìˆ˜</div>
            </div>
            <div class="stat-card">
                <div class="stat-value">{total_pdf}</div>
                <div class="stat-label">PDF í™•ë³´</div>
            </div>
            <div class="stat-card">
                <div class="stat-value">{total_data}</div>
                <div class="stat-label">ë°ì´í„° ì¶”ì¶œ</div>
            </div>
            <div class="stat-card">
                <div class="stat-value">101</div>
                <div class="stat-label">ì°¸ê³  ë°ì´í„°</div>
            </div>
        </div>
        
        <div class="progress-bar">
            <div class="progress-fill" style="width: {(total_papers/60*100):.1f}%">
                {(total_papers/60*100):.1f}% ì™„ë£Œ
            </div>
        </div>
        
        <div class="section">
            <div class="section-title">ğŸ“Š ë°°ì¹˜ë³„ ìˆ˜ì§‘ ê²°ê³¼</div>
            <table class="batch-table">
                <thead>
                    <tr>
                        <th>íŒŒì¼ëª…</th>
                        <th>ë…¼ë¬¸ ìˆ˜</th>
                        <th>PDF í™•ë³´</th>
                        <th>ë°ì´í„° ì¶”ì¶œ</th>
                        <th>ì„±ê³µë¥ </th>
                    </tr>
                </thead>
                <tbody>
"""
    
    for batch in batch_info:
        success_rate = (batch['data'] / batch['papers'] * 100) if batch['papers'] > 0 else 0
        html_content += f"""
                    <tr>
                        <td>{batch['file']}</td>
                        <td>{batch['papers']}ê°œ</td>
                        <td>{batch['pdf']}ê°œ</td>
                        <td>{batch['data']}ê°œ</td>
                        <td>{success_rate:.1f}%</td>
                    </tr>
"""
    
    html_content += """
                </tbody>
            </table>
        </div>
        
        <div class="section">
            <div class="section-title">ğŸ¯ í”„ë¡œì íŠ¸ ëª©í‘œ</div>
            <ul style="font-size: 1.1em; line-height: 2em; margin-left: 20px;">
                <li>âœ… ì°¸ê³  ë°ì´í„°: 101 ìƒ˜í”Œ í™•ë³´</li>
                <li>âœ… ë³‘ë ¬ ì²˜ë¦¬ ì‹œìŠ¤í…œ êµ¬ì¶• (4ê°œ ì›Œì»¤)</li>
                <li>ğŸ”„ ìë™ ë°ì´í„° ìˆ˜ì§‘ (60ê°œ ë…¼ë¬¸ ëª©í‘œ)</li>
                <li>ğŸ“Š Feature Engineering (30+ ë³€ìˆ˜)</li>
                <li>ğŸ¤– ML ëª¨ë¸ í•™ìŠµ (SVR, RF, GBM)</li>
                <li>ğŸ¯ íŠ¹ì„± ì˜ˆì¸¡ ì‹œìŠ¤í…œ ì™„ì„±</li>
            </ul>
        </div>
    </div>
    
    <script>
        // ìë™ ìƒˆë¡œê³ ì¹¨ (5ì´ˆë§ˆë‹¤)
        setTimeout(() => location.reload(), 5000);
    </script>
</body>
</html>
"""
    
    output_file.write_text(html_content, encoding='utf-8')


def show_collection_results():
    """ìˆ˜ì§‘ ê²°ê³¼ í‘œì‹œ"""
    import pandas as pd
    
    project_root = Path(__file__).parent.parent
    data_dir = project_root / "data"
    
    collected_files = sorted(data_dir.glob("parallel_collected_*.csv"), reverse=True)
    
    if not collected_files:
        print("âŒ ìˆ˜ì§‘ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    print(f"ğŸ“Š ì´ {len(collected_files)}ê°œ ë°°ì¹˜ ë°œê²¬\n")
    
    for i, file in enumerate(collected_files, 1):
        try:
            df = pd.read_csv(file)
            has_pdf = sum(df.get('Cl_source', pd.Series()).notna())
            has_data = sum(df.get('size_nm', pd.Series()).notna())
            
            print(f"{i}. {file.name}")
            print(f"   ë…¼ë¬¸: {len(df)}ê°œ | PDF: {has_pdf}ê°œ | ë°ì´í„°: {has_data}ê°œ")
            print()
        except Exception as e:
            print(f"   âŒ ì˜¤ë¥˜: {e}\n")


def manage_queue():
    """DOI í ê´€ë¦¬"""
    project_root = Path(__file__).parent.parent
    queue_file = project_root / "data" / "papers_queue.txt"
    
    if not queue_file.exists():
        print("âŒ papers_queue.txt íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    lines = queue_file.read_text().strip().split('\n')
    dois = [line.strip() for line in lines if line.strip() and not line.startswith('#')]
    
    print(f"ğŸ“‹ í˜„ì¬ íì— {len(dois)}ê°œ DOIê°€ ìˆìŠµë‹ˆë‹¤.\n")
    print("ìµœê·¼ 10ê°œ:")
    for i, doi in enumerate(dois[:10], 1):
        print(f"   {i}. {doi}")
    
    if len(dois) > 10:
        print(f"   ... ì™¸ {len(dois)-10}ê°œ")


def main():
    """ë©”ì¸ í•¨ìˆ˜ - ëŒ€í™”í˜• ë©”ë‰´"""
    while True:
        choice = show_menu()
        handle_choice(choice)
        
        if choice in ["1", "4", "5"]:
            input("\n\nâ¸ï¸  Enterë¥¼ ëˆŒëŸ¬ ë©”ë‰´ë¡œ ëŒì•„ê°€ê¸°...")


if __name__ == "__main__":
    main()
