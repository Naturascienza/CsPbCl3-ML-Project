#!/usr/bin/env python3
"""
ìë™ DOI ê²€ìƒ‰ ë° ëŒ€ê·œëª¨ ìˆ˜ì§‘ ì‹œìŠ¤í…œ
CrossRef APIë¡œ CsPbCl3 ê´€ë ¨ ë…¼ë¬¸ ìë™ ê²€ìƒ‰ â†’ PDF ë‹¤ìš´ë¡œë“œ â†’ ë°ì´í„° ì¶”ì¶œ
"""

import requests
import time
from pathlib import Path
from typing import List, Dict
import logging

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class AutoDOICollector:
    """ìë™ DOI ê²€ìƒ‰ ë° ìˆ˜ì§‘"""
    
    def __init__(self):
        self.crossref_api = "https://api.crossref.org/works"
        self.email = "your_email@example.com"  # CrossRef ì •ì±…: ì´ë©”ì¼ ì¶”ê°€
        
    def search_crossref(
        self, 
        query: str, 
        limit: int = 50,
        filter_params: Dict = None
    ) -> List[Dict]:
        """
        CrossRef APIë¡œ ë…¼ë¬¸ ê²€ìƒ‰
        
        Args:
            query: ê²€ìƒ‰ í‚¤ì›Œë“œ
            limit: ìµœëŒ€ ê²°ê³¼ ìˆ˜
            filter_params: í•„í„° (ì˜ˆ: has-full-text, type:journal-article)
        
        Returns:
            ë…¼ë¬¸ ë©”íƒ€ë°ì´í„° ë¦¬ìŠ¤íŠ¸
        """
        results = []
        params = {
            'query': query,
            'rows': min(limit, 100),  # API ì œí•œ
            'mailto': self.email,
            'select': 'DOI,title,author,published-print,container-title',
        }
        
        # í•„í„° ì¶”ê°€
        if filter_params:
            filters = []
            for key, value in filter_params.items():
                filters.append(f"{key}:{value}")
            params['filter'] = ','.join(filters)
        
        logger.info(f"ğŸ” CrossRef ê²€ìƒ‰: '{query}' (ìµœëŒ€ {limit}ê°œ)")
        
        try:
            response = requests.get(
                self.crossref_api,
                params=params,
                timeout=30
            )
            response.raise_for_status()
            
            data = response.json()
            items = data.get('message', {}).get('items', [])
            
            for item in items:
                doi = item.get('DOI')
                title = item.get('title', ['No title'])[0]
                
                results.append({
                    'doi': doi,
                    'title': title,
                    'authors': self._format_authors(item.get('author', [])),
                    'journal': item.get('container-title', [''])[0],
                    'year': self._extract_year(item),
                })
            
            logger.info(f"âœ… {len(results)}ê°œ ë…¼ë¬¸ ë°œê²¬")
            return results
            
        except Exception as e:
            logger.error(f"âŒ CrossRef ê²€ìƒ‰ ì‹¤íŒ¨: {str(e)}")
            return []
    
    def _format_authors(self, authors: List[Dict]) -> str:
        """ì €ì ì´ë¦„ í¬ë§·íŒ…"""
        if not authors:
            return ""
        
        names = []
        for author in authors[:3]:  # ì²˜ìŒ 3ëª…ë§Œ
            given = author.get('given', '')
            family = author.get('family', '')
            if family:
                names.append(f"{given} {family}".strip())
        
        if len(authors) > 3:
            names.append("et al.")
        
        return ", ".join(names)
    
    def _extract_year(self, item: Dict) -> int:
        """ì¶œíŒ ì—°ë„ ì¶”ì¶œ"""
        pub_date = item.get('published-print', item.get('published-online', {}))
        date_parts = pub_date.get('date-parts', [[]])[0]
        return date_parts[0] if date_parts else 0
    
    def filter_relevant_papers(
        self, 
        papers: List[Dict],
        keywords: List[str] = None
    ) -> List[Dict]:
        """
        ê´€ë ¨ ë…¼ë¬¸ í•„í„°ë§
        
        Args:
            papers: ë…¼ë¬¸ ë¦¬ìŠ¤íŠ¸
            keywords: í•„ìˆ˜ í‚¤ì›Œë“œ (ì œëª©ì— í¬í•¨ë˜ì–´ì•¼ í•¨)
        
        Returns:
            í•„í„°ë§ëœ ë…¼ë¬¸ ë¦¬ìŠ¤íŠ¸
        """
        if not keywords:
            keywords = ['cspbcl3', 'quantum dot', 'perovskite', 'synthesis']
        
        filtered = []
        for paper in papers:
            title_lower = paper['title'].lower()
            
            # í‚¤ì›Œë“œ ì¤‘ í•˜ë‚˜ë¼ë„ í¬í•¨
            if any(kw.lower() in title_lower for kw in keywords):
                filtered.append(paper)
        
        logger.info(f"ğŸ” í•„í„°ë§: {len(filtered)}/{len(papers)} ë…¼ë¬¸ ì„ íƒ")
        return filtered
    
    def save_to_queue(self, papers: List[Dict], queue_file: Path):
        """DOI íì— ì €ì¥"""
        existing_dois = set()
        
        # ê¸°ì¡´ DOI ì½ê¸°
        if queue_file.exists():
            with open(queue_file, 'r') as f:
                existing_dois = {line.strip() for line in f if line.strip()}
        
        # ìƒˆ DOI ì¶”ê°€
        new_dois = []
        for paper in papers:
            doi = paper['doi']
            if doi and doi not in existing_dois:
                new_dois.append(doi)
                existing_dois.add(doi)
        
        # íŒŒì¼ì— ì¶”ê°€
        if new_dois:
            with open(queue_file, 'a') as f:
                for doi in new_dois:
                    f.write(f"{doi}\n")
            
            logger.info(f"âœ… {len(new_dois)}ê°œ ìƒˆ DOIë¥¼ íì— ì¶”ê°€")
        else:
            logger.info("âš ï¸ ì¶”ê°€í•  ìƒˆ DOI ì—†ìŒ (ëª¨ë‘ ì¤‘ë³µ)")

def main():
    """ìë™ DOI ê²€ìƒ‰ ë° ìˆ˜ì§‘"""
    
    print("="*80)
    print("ğŸ” CsPbCl3 ë…¼ë¬¸ ìë™ ê²€ìƒ‰ ì‹œìŠ¤í…œ")
    print("="*80)
    
    # í”„ë¡œì íŠ¸ ê²½ë¡œ
    project_root = Path(__file__).parent.parent
    queue_file = project_root / "data" / "papers_queue.txt"
    
    # ìˆ˜ì§‘ê¸° ì´ˆê¸°í™”
    collector = AutoDOICollector()
    
    # ê²€ìƒ‰ ì¿¼ë¦¬ (ì—¬ëŸ¬ ë³€í˜•)
    queries = [
        "CsPbCl3 quantum dots synthesis",
        "cesium lead chloride QDs",
        "CsPbCl3 perovskite nanocrystals",
        "all-inorganic perovskite CsPbCl3",
        "hot injection CsPbCl3",
    ]
    
    all_papers = []
    
    for query in queries:
        print(f"\n{'='*80}")
        print(f"ğŸ” ê²€ìƒ‰: '{query}'")
        print("="*80)
        
        papers = collector.search_crossref(
            query=query,
            limit=20,  # ê° ì¿¼ë¦¬ë‹¹ 20ê°œ
            filter_params={
                'type': 'journal-article',
                'has-full-text': 'true'
            }
        )
        
        all_papers.extend(papers)
        time.sleep(1)  # API ì œí•œ ì¤€ìˆ˜
    
    # ì¤‘ë³µ ì œê±° (DOI ê¸°ì¤€)
    unique_papers = {}
    for paper in all_papers:
        doi = paper['doi']
        if doi and doi not in unique_papers:
            unique_papers[doi] = paper
    
    papers_list = list(unique_papers.values())
    
    print(f"\n{'='*80}")
    print(f"ğŸ“Š ê²€ìƒ‰ ê²°ê³¼")
    print("="*80)
    print(f"   - ì´ ë…¼ë¬¸ ìˆ˜: {len(all_papers)}")
    print(f"   - ì¤‘ë³µ ì œê±° í›„: {len(papers_list)}")
    
    # ê´€ë ¨ ë…¼ë¬¸ í•„í„°ë§
    filtered = collector.filter_relevant_papers(
        papers_list,
        keywords=['cspbcl3', 'quantum dot', 'perovskite']
    )
    
    # íì— ì €ì¥
    print(f"\n{'='*80}")
    print(f"ğŸ’¾ DOI íì— ì €ì¥")
    print("="*80)
    collector.save_to_queue(filtered, queue_file)
    
    # ê²°ê³¼ ìš”ì•½
    print(f"\n{'='*80}")
    print(f"âœ… ì™„ë£Œ!")
    print("="*80)
    print(f"   - ìƒˆ DOI: {len(filtered)}ê°œ")
    print(f"   - í íŒŒì¼: {queue_file}")
    print(f"\nğŸ’¡ ë‹¤ìŒ ë‹¨ê³„:")
    print(f"   python scripts/auto_data_collector.py")
    print("="*80)

if __name__ == "__main__":
    main()
