#!/usr/bin/env python3
"""
DOI ê²€ì¦ ë° CrossRef ê²€ìƒ‰ ìŠ¤í¬ë¦½íŠ¸
ì‹¤ì œ ì¡´ì¬í•˜ëŠ” CsPbCl3 ê´€ë ¨ ë…¼ë¬¸ DOIë¥¼ ì°¾ìŠµë‹ˆë‹¤.
"""

import requests
import time
from typing import List, Dict
import json

def validate_doi(doi: str) -> bool:
    """DOIê°€ ì‹¤ì œë¡œ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸"""
    try:
        response = requests.head(f"https://doi.org/{doi}", timeout=5, allow_redirects=True)
        return response.status_code in [200, 302]
    except:
        return False

def search_crossref(query: str, rows: int = 20) -> List[Dict]:
    """CrossRef APIë¡œ ë…¼ë¬¸ ê²€ìƒ‰"""
    url = "https://api.crossref.org/works"
    params = {
        "query": query,
        "rows": rows,
        "select": "DOI,title,published,container-title,author",
        "filter": "type:journal-article"
    }
    
    try:
        response = requests.get(url, params=params, timeout=10)
        if response.status_code == 200:
            data = response.json()
            return data.get('message', {}).get('items', [])
    except Exception as e:
        print(f"Error searching CrossRef: {e}")
    
    return []

def validate_existing_dois(csv_file: str) -> Dict[str, bool]:
    """CSV íŒŒì¼ì˜ DOIë“¤ì„ ê²€ì¦"""
    import pandas as pd
    
    print("ğŸ“‹ ê¸°ì¡´ DOI ê²€ì¦ ì¤‘...")
    df = pd.read_csv(csv_file)
    unique_dois = df['doi'].unique()
    
    results = {}
    valid_count = 0
    invalid_count = 0
    
    for i, doi in enumerate(unique_dois, 1):
        is_valid = validate_doi(doi)
        results[doi] = is_valid
        
        if is_valid:
            print(f"  âœ… [{i}/{len(unique_dois)}] {doi}")
            valid_count += 1
        else:
            print(f"  âŒ [{i}/{len(unique_dois)}] {doi}")
            invalid_count += 1
        
        time.sleep(0.5)  # Rate limiting
    
    print(f"\nğŸ“Š ê²€ì¦ ê²°ê³¼:")
    print(f"  - ìœ íš¨: {valid_count}ê°œ ({valid_count/len(unique_dois)*100:.1f}%)")
    print(f"  - ë¬´íš¨: {invalid_count}ê°œ ({invalid_count/len(unique_dois)*100:.1f}%)")
    
    return results

def search_cspbcl3_papers() -> List[Dict]:
    """CsPbCl3 ê´€ë ¨ ë…¼ë¬¸ ê²€ìƒ‰"""
    print("\nğŸ” CsPbCl3 ë…¼ë¬¸ ê²€ìƒ‰ ì¤‘...\n")
    
    search_queries = [
        "CsPbCl3 perovskite quantum dots",
        "cesium lead chloride quantum dots",
        "CsPbCl3 nanocrystals synthesis",
        "CsPbCl3 colloidal quantum dots",
        "cesium lead halide perovskite CsPbCl3"
    ]
    
    all_papers = []
    seen_dois = set()
    
    for query in search_queries:
        print(f"  ê²€ìƒ‰ì–´: '{query}'")
        papers = search_crossref(query, rows=15)
        
        for paper in papers:
            doi = paper.get('DOI', '')
            if doi and doi not in seen_dois:
                # CsPbCl3 ê´€ë ¨ì„± í™•ì¸
                title = paper.get('title', [''])[0].lower()
                if any(keyword in title for keyword in ['cspbcl3', 'cesium lead chloride', 'perovskite', 'quantum dot']):
                    seen_dois.add(doi)
                    all_papers.append(paper)
        
        time.sleep(1)  # Rate limiting
    
    print(f"\n  âœ… ì´ {len(all_papers)}ê°œì˜ ê³ ìœ  ë…¼ë¬¸ ë°œê²¬\n")
    return all_papers

def save_validated_dois(papers: List[Dict], output_file: str):
    """ê²€ì¦ëœ DOIë¥¼ íŒŒì¼ë¡œ ì €ì¥"""
    print("ğŸ’¾ ê²€ì¦ëœ DOI ì €ì¥ ì¤‘...")
    
    validated_papers = []
    
    for i, paper in enumerate(papers, 1):
        doi = paper.get('DOI', '')
        if validate_doi(doi):
            title = paper.get('title', ['Unknown'])[0]
            year = paper.get('published', {}).get('date-parts', [[0]])[0][0]
            journal = paper.get('container-title', ['Unknown'])[0]
            
            validated_papers.append({
                'doi': doi,
                'title': title[:100],
                'year': year,
                'journal': journal[:50]
            })
            
            print(f"  âœ… [{i}/{len(papers)}] {doi}")
            print(f"      {title[:80]}")
        else:
            print(f"  âŒ [{i}/{len(papers)}] {doi} (ë¬´íš¨)")
        
        time.sleep(0.5)
    
    # JSONìœ¼ë¡œ ì €ì¥
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(validated_papers, f, indent=2, ensure_ascii=False)
    
    print(f"\nâœ… {len(validated_papers)}ê°œì˜ ìœ íš¨í•œ ë…¼ë¬¸ì„ {output_file}ì— ì €ì¥í–ˆìŠµë‹ˆë‹¤.")
    
    return validated_papers

def main():
    print("=" * 70)
    print("ğŸ”¬ CsPbCl3 ë…¼ë¬¸ DOI ê²€ì¦ ë° ê²€ìƒ‰")
    print("=" * 70)
    
    # 1. ê¸°ì¡´ DOI ê²€ì¦
    csv_file = "data/literature_data_collected.csv"
    existing_validation = validate_existing_dois(csv_file)
    
    # 2. ìƒˆë¡œìš´ ë…¼ë¬¸ ê²€ìƒ‰
    new_papers = search_cspbcl3_papers()
    
    # 3. ê²€ì¦ ë° ì €ì¥
    output_file = "data/validated_dois.json"
    validated = save_validated_dois(new_papers, output_file)
    
    # 4. papers_queue.txt ì—…ë°ì´íŠ¸ìš© DOI ë¦¬ìŠ¤íŠ¸ ìƒì„±
    print("\nğŸ“ papers_queue.txt ì—…ë°ì´íŠ¸ìš© DOI:")
    print("-" * 70)
    for paper in validated[:30]:  # ìƒìœ„ 30ê°œë§Œ
        print(paper['doi'])
    
    print("\n" + "=" * 70)
    print("âœ… ì™„ë£Œ!")
    print(f"   ê²€ì¦ëœ DOI: {len(validated)}ê°œ")
    print(f"   ì €ì¥ ìœ„ì¹˜: {output_file}")
    print("=" * 70)

if __name__ == "__main__":
    main()
