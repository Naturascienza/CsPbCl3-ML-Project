#!/usr/bin/env python3
"""
PDF ìë™ ë°ì´í„° ì¶”ì¶œ ëª¨ë“ˆ
ë…¼ë¬¸ PDFì—ì„œ í•©ì„± ì¡°ê±´ê³¼ íŠ¹ì„± ë°ì´í„°ë¥¼ ìë™ìœ¼ë¡œ ì¶”ì¶œ
Seleniumì„ í†µí•œ ê¸°ê´€ êµ¬ë… í™œìš© ì§€ì›
"""

import re
import requests
import pdfplumber
from pathlib import Path
from typing import Dict, Optional, List
import logging
import time
import glob
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.chrome.service import Service
from webdriver_manager.chrome import ChromeDriverManager

logger = logging.getLogger(__name__)

class PDFDataExtractor:
    """PDFì—ì„œ CsPbCl3 í•©ì„± ë°ì´í„° ì¶”ì¶œ"""
    
    def __init__(self, pdf_dir: Path, use_selenium: bool = True):
        self.pdf_dir = pdf_dir
        self.pdf_dir.mkdir(exist_ok=True)
        self.use_selenium = use_selenium
        self.driver = None
        
        if use_selenium:
            self._init_selenium()
    
    def _init_selenium(self):
        """Selenium ì›¹ë“œë¼ì´ë²„ ì´ˆê¸°í™” (ì™„ì „ headless)"""
        try:
            chrome_options = Options()
            
            # ì™„ì „ headless ëª¨ë“œ (í™”ë©´ì— ì ˆëŒ€ ì•ˆ ë³´ì„!)
            chrome_options.add_argument('--headless=new')  # ìƒˆë¡œìš´ headless ëª¨ë“œ
            chrome_options.add_argument('--no-sandbox')
            chrome_options.add_argument('--disable-dev-shm-usage')
            chrome_options.add_argument('--disable-gpu')
            chrome_options.add_argument('--window-size=1920,1080')
            chrome_options.add_argument('--disable-extensions')
            chrome_options.add_argument('--disable-notifications')
            chrome_options.add_argument('--disable-popup-blocking')
            
            # í™”ë©´ ë°–ìœ¼ë¡œ ì´ë™ (ì¶”ê°€ ì•ˆì „ì¥ì¹˜)
            chrome_options.add_argument('--window-position=-2400,-2400')
            
            # ë°±ê·¸ë¼ìš´ë“œ ì‹¤í–‰
            chrome_options.add_argument('--disable-background-timer-throttling')
            chrome_options.add_argument('--disable-backgrounding-occluded-windows')
            chrome_options.add_argument('--disable-renderer-backgrounding')
            
            # ë‹¤ìš´ë¡œë“œ ì„¤ì •
            prefs = {
                "download.default_directory": str(self.pdf_dir.absolute()),
                "download.prompt_for_download": False,
                "download.directory_upgrade": True,
                "plugins.always_open_pdf_externally": True,
                "profile.default_content_setting_values.automatic_downloads": 1,
            }
            chrome_options.add_experimental_option("prefs", prefs)
            chrome_options.add_experimental_option('excludeSwitches', ['enable-logging'])
            
            # ChromeDriver ìë™ ì„¤ì¹˜ ë° ì„¤ì •
            service = Service(ChromeDriverManager().install())
            service.log_path = '/dev/null'  # ë¡œê·¸ ìˆ¨ê¹€
            
            self.driver = webdriver.Chrome(service=service, options=chrome_options)
            logger.info("âœ… Selenium ì›¹ë“œë¼ì´ë²„ ì´ˆê¸°í™” ì™„ë£Œ (ì™„ì „ headless ëª¨ë“œ - í™”ë©´ ë°©í•´ ì—†ìŒ)")
        except Exception as e:
            logger.warning(f"âš ï¸ Selenium ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            logger.warning("ê¸°ë³¸ requests ë°©ì‹ìœ¼ë¡œ ì „í™˜í•©ë‹ˆë‹¤.")
            self.use_selenium = False
    
    def __del__(self):
        """ì†Œë©¸ì: ì›¹ë“œë¼ì´ë²„ ì¢…ë£Œ"""
        if self.driver:
            try:
                self.driver.quit()
            except:
                pass
    
    def _download_with_selenium(self, doi: str, pdf_path: Path) -> bool:
        """Seleniumì„ í†µí•œ PDF ë‹¤ìš´ë¡œë“œ (ê¸°ê´€ êµ¬ë… í™œìš©)"""
        if not self.driver:
            return False
        
        try:
            doi_url = f"https://doi.org/{doi}"
            logger.info(f"ğŸŒ ë¸Œë¼ìš°ì €ë¡œ ì ‘ê·¼ ì¤‘: {doi_url}")
            
            self.driver.get(doi_url)
            time.sleep(5)  # í˜ì´ì§€ ë¡œë“œ ëŒ€ê¸° (ë” ê¸¸ê²Œ)
            
            # ì¿ í‚¤ ë°°ë„ˆ ë‹«ê¸° ì‹œë„ (ì—¬ëŸ¬ íŒ¨í„´)
            cookie_close_selectors = [
                "button.cc-dismiss",  # ì¼ë°˜ì ì¸ ì¿ í‚¤ ë‹«ê¸°
                "button[aria-label='Close']",
                "button.cookie-consent-close",
                "//button[contains(text(), 'Accept')]",
                "//button[contains(text(), 'Reject')]",
                "//button[contains(text(), 'Close')]"
            ]
            
            for selector in cookie_close_selectors:
                try:
                    if selector.startswith("//"):
                        # XPath
                        btn = self.driver.find_element(By.XPATH, selector)
                    else:
                        # CSS
                        btn = self.driver.find_element(By.CSS_SELECTOR, selector)
                    btn.click()
                    logger.info("âœ… ì¿ í‚¤ ë°°ë„ˆ ë‹«ê¸° ì„±ê³µ")
                    time.sleep(1)
                    break
                except:
                    continue
            
            # PDF ë§í¬ ì°¾ê¸° (ì—¬ëŸ¬ ë°©ë²• ì‹œë„)
            pdf_link = None
            
            # ë°©ë²• 1: í…ìŠ¤íŠ¸ë¡œ ì°¾ê¸°
            pdf_link_texts = [
                "Download PDF", "PDF", "View PDF", "Full Text PDF",
                "Download Article", "Article PDF", "Full-text PDF",
                "Download", "Full Text", "Article"
            ]
            
            for link_text in pdf_link_texts:
                try:
                    links = self.driver.find_elements(By.PARTIAL_LINK_TEXT, link_text)
                    for link in links:
                        href = link.get_attribute('href')
                        if href and ('.pdf' in href or 'pdf' in href.lower()):
                            pdf_link = link
                            logger.info(f"âœ… PDF ë§í¬ ë°œê²¬ (í…ìŠ¤íŠ¸): '{link_text}'")
                            break
                    if pdf_link:
                        break
                except:
                    continue
            
            # ë°©ë²• 2: CSS Selectorë¡œ ì°¾ê¸°
            if not pdf_link:
                pdf_selectors = [
                    "a[href*='.pdf']",
                    "a[data-article-pdf='true']",
                    "a.pdf-download",
                    "a.download-pdf",
                    "a[href*='pdf']",
                    "button[data-test='pdf-download']"
                ]
                
                for selector in pdf_selectors:
                    try:
                        pdf_link = self.driver.find_element(By.CSS_SELECTOR, selector)
                        logger.info(f"âœ… PDF ë§í¬ ë°œê²¬ (CSS): {selector}")
                        break
                    except:
                        continue
            
            # ë°©ë²• 3: XPathë¡œ ì°¾ê¸°
            if not pdf_link:
                pdf_xpaths = [
                    "//a[contains(@href, '.pdf')]",
                    "//a[contains(text(), 'PDF')]",
                    "//button[contains(text(), 'PDF')]",
                ]
                
                for xpath in pdf_xpaths:
                    try:
                        pdf_link = self.driver.find_element(By.XPATH, xpath)
                        logger.info(f"âœ… PDF ë§í¬ ë°œê²¬ (XPath): {xpath}")
                        break
                    except:
                        continue
            
            if pdf_link:
                # JavaScriptë¡œ í´ë¦­ (ë°°ë„ˆ ìš°íšŒ)
                try:
                    self.driver.execute_script("arguments[0].click();", pdf_link)
                    logger.info("ğŸ“¥ PDF ë‹¤ìš´ë¡œë“œ ì‹œì‘ (JavaScript í´ë¦­)...")
                except:
                    # ì¼ë°˜ í´ë¦­ ì‹œë„
                    try:
                        pdf_link.click()
                        logger.info("ğŸ“¥ PDF ë‹¤ìš´ë¡œë“œ ì‹œì‘ (ì¼ë°˜ í´ë¦­)...")
                    except:
                        # href ì§ì ‘ ì ‘ê·¼
                        href = pdf_link.get_attribute('href')
                        if href:
                            self.driver.get(href)
                            logger.info("ğŸ“¥ PDF ë‹¤ìš´ë¡œë“œ ì‹œì‘ (URL ì§ì ‘ ì ‘ê·¼)...")
                
                # ë‹¤ìš´ë¡œë“œ ì™„ë£Œ ëŒ€ê¸° (ìµœëŒ€ 60ì´ˆ)
                before_files = set(glob.glob(str(self.pdf_dir / "*.pdf")))
                
                for i in range(60):
                    time.sleep(1)
                    after_files = set(glob.glob(str(self.pdf_dir / "*.pdf")))
                    new_files = after_files - before_files
                    
                    if new_files:
                        # ìƒˆ íŒŒì¼ì´ ìƒì„±ë¨
                        downloaded_file = Path(list(new_files)[0])
                        
                        # íŒŒì¼ëª… ë³€ê²½
                        downloaded_file.rename(pdf_path)
                        logger.info(f"âœ… PDF ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: {pdf_path.name}")
                        return True
                
                logger.warning("âš ï¸ PDF ë‹¤ìš´ë¡œë“œ íƒ€ì„ì•„ì›ƒ (60ì´ˆ)")
                return False
            else:
                logger.warning("âš ï¸ PDF ë§í¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ")
                
                # í˜ì´ì§€ ì†ŒìŠ¤ ë¶„ì„ (ë””ë²„ê¹…)
                if 'pdf' in self.driver.page_source.lower():
                    logger.debug("ğŸ’¡ í˜ì´ì§€ì— 'pdf' í…ìŠ¤íŠ¸ ì¡´ì¬ - ë‹¤ë¥¸ ì ‘ê·¼ ë°©ë²• í•„ìš”")
                
                return False
                
        except Exception as e:
            logger.error(f"âŒ Selenium ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {e}")
            return False
    
    def download_pdf(self, doi: str) -> Optional[Path]:
        """PDF ë‹¤ìš´ë¡œë“œ (ì—¬ëŸ¬ ì†ŒìŠ¤ ì‹œë„)"""
        
        # 1. ì´ë¯¸ ë‹¤ìš´ë¡œë“œëœ PDF í™•ì¸
        pdf_path = self.pdf_dir / f"{doi.replace('/', '_')}.pdf"
        if pdf_path.exists():
            logger.info(f"âœ… ê¸°ì¡´ PDF ì‚¬ìš©: {pdf_path.name}")
            return pdf_path
        
        # 2. Seleniumì„ í†µí•œ ë‹¤ìš´ë¡œë“œ ì‹œë„ (ê¸°ê´€ êµ¬ë… í™œìš©) â­ ì‹ ê·œ!
        if self.use_selenium:
            logger.info(f"ğŸ” Seleniumìœ¼ë¡œ PDF ë‹¤ìš´ë¡œë“œ ì‹œë„: {doi}")
            if self._download_with_selenium(doi, pdf_path):
                return pdf_path
        
        # 3. Unpaywall API ì‹œë„
        email = "research@example.com"
        url = f"https://api.unpaywall.org/v2/{doi}?email={email}"
        
        try:
            logger.info(f"ğŸ” Unpaywall PDF ê²€ìƒ‰ ì¤‘: {doi}")
            response = requests.get(url, timeout=10)
            
            if response.status_code == 200:
                data = response.json()
                
                # ì˜¤í”ˆì•¡ì„¸ìŠ¤ PDF URL ì°¾ê¸°
                pdf_url = None
                if data.get('is_oa'):
                    best_oa = data.get('best_oa_location', {})
                    pdf_url = best_oa.get('url_for_pdf')
                
                if pdf_url:
                    logger.info(f"ğŸ“¥ PDF ë‹¤ìš´ë¡œë“œ ì¤‘: {pdf_url}")
                    pdf_response = requests.get(pdf_url, timeout=30, headers={
                        'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7)'
                    })
                    
                    if pdf_response.status_code == 200:
                        pdf_path.write_bytes(pdf_response.content)
                        logger.info(f"âœ… PDF ì €ì¥: {pdf_path.name}")
                        return pdf_path
        
        except Exception as e:
            logger.debug(f"Unpaywall ì‹¤íŒ¨: {e}")
        
        # 4. DOI.org ì§ì ‘ ì ‘ê·¼ ì‹œë„
        try:
            logger.info(f"ğŸ”— DOI.org ì ‘ê·¼ ì‹œë„: {doi}")
            doi_url = f"https://doi.org/{doi}"
            response = requests.get(doi_url, timeout=10, allow_redirects=True, headers={
                'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7)',
                'Accept': 'application/pdf'
            })
            
            # PDFì¸ì§€ í™•ì¸
            if 'application/pdf' in response.headers.get('Content-Type', ''):
                pdf_path.write_bytes(response.content)
                logger.info(f"âœ… DOI.orgì—ì„œ PDF ì €ì¥: {pdf_path.name}")
                return pdf_path
        
        except Exception as e:
            logger.debug(f"DOI.org ì ‘ê·¼ ì‹¤íŒ¨: {e}")
        
        logger.warning(f"âš ï¸  PDF ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨ (ëª¨ë“  ì†ŒìŠ¤): {doi}")
        return None
    
    def extract_text_from_pdf(self, pdf_path: Path) -> str:
        """PDFì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
        try:
            text = ""
            with pdfplumber.open(pdf_path) as pdf:
                for page in pdf.pages:
                    page_text = page.extract_text()
                    if page_text:
                        text += page_text + "\n"
            return text
        except Exception as e:
            logger.error(f"âŒ PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return ""
    
    def extract_tables_from_pdf(self, pdf_path: Path) -> list:
        """PDFì—ì„œ í‘œ ì¶”ì¶œ (ìƒˆë¡œìš´ ê¸°ëŠ¥!)"""
        try:
            tables = []
            with pdfplumber.open(pdf_path) as pdf:
                for page_num, page in enumerate(pdf.pages, 1):
                    page_tables = page.extract_tables()
                    if page_tables:
                        logger.info(f"   í˜ì´ì§€ {page_num}: {len(page_tables)}ê°œ í‘œ ë°œê²¬")
                        tables.extend(page_tables)
            
            if tables:
                logger.info(f"âœ… ì´ {len(tables)}ê°œ í‘œ ì¶”ì¶œ")
            return tables
        except Exception as e:
            logger.debug(f"í‘œ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return []
    
    def parse_synthesis_from_table(self, tables: list) -> Dict:
        """í‘œì—ì„œ í•©ì„± ì¡°ê±´ íŒŒì‹±"""
        data = {}
        
        for table in tables:
            if not table or len(table) < 2:
                continue
            
            # í‘œë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜í•˜ì—¬ ë¶„ì„
            table_text = ' '.join([' '.join([str(cell) for cell in row if cell]) 
                                  for row in table]).lower()
            
            # CsPbCl3 í•©ì„± ê´€ë ¨ í‘œì¸ì§€ í™•ì¸
            if not ('cspbcl3' in table_text or 'perovskite' in table_text or 
                    'quantum dot' in table_text or 'pbcl2' in table_text):
                continue
            
            logger.info("   âœ… CsPbCl3 í•©ì„± ê´€ë ¨ í‘œ ë°œê²¬")
            
            # í‘œì—ì„œ ê°’ ì¶”ì¶œ (í–‰ ê¸°ë°˜)
            for row in table[1:]:  # ì²« í–‰ì€ í—¤ë”
                if not row:
                    continue
                
                row_text = ' '.join([str(cell).lower() for cell in row if cell])
                
                # ì˜¨ë„ (100-250Â°C ë²”ìœ„)
                if 'temp' in row_text or 'injection' in row_text:
                    for cell in row:
                        if cell and str(cell).replace('.', '').isdigit():
                            temp = float(cell)
                            if 100 <= temp <= 250:
                                data['injection_temp_C'] = temp
                                break
                
                # ì „êµ¬ì²´ ì–‘
                if 'pbcl2' in row_text or 'lead' in row_text:
                    for cell in row:
                        if cell and isinstance(cell, (int, float)):
                            if 0.01 <= cell <= 10:  # mmol ë²”ìœ„
                                data['Pb_amount_mmol'] = cell
                
                # ë¦¬ê°„ë“œ
                if 'oa' in row_text and 'oleic' in row_text:
                    for cell in row:
                        if cell and isinstance(cell, (int, float)):
                            if 0.1 <= cell <= 20:  # mL ë²”ìœ„
                                data['OA_volume_ml'] = cell
                
                if 'ola' in row_text or 'oleylamine' in row_text:
                    for cell in row:
                        if cell and isinstance(cell, (int, float)):
                            if 0.1 <= cell <= 20:
                                data['OLA_volume_ml'] = cell
                
                if 'ode' in row_text or 'octadecene' in row_text:
                    for cell in row:
                        if cell and isinstance(cell, (int, float)):
                            if 1 <= cell <= 50:
                                data['ODE_volume_ml'] = cell
        
        return data
    
    def parse_properties_from_table(self, tables: list) -> Dict:
        """í‘œì—ì„œ QD íŠ¹ì„± íŒŒì‹±"""
        data = {}
        
        for table in tables:
            if not table or len(table) < 2:
                continue
            
            table_text = ' '.join([' '.join([str(cell) for cell in row if cell]) 
                                  for row in table]).lower()
            
            # íŠ¹ì„± ê´€ë ¨ í‘œì¸ì§€ í™•ì¸
            if not ('pl' in table_text or 'plqy' in table_text or 
                    'size' in table_text or 'emission' in table_text):
                continue
            
            logger.info("   âœ… QD íŠ¹ì„± ê´€ë ¨ í‘œ ë°œê²¬")
            
            for row in table[1:]:
                if not row:
                    continue
                
                row_text = ' '.join([str(cell).lower() for cell in row if cell])
                
                # í¬ê¸°
                if 'size' in row_text or 'diameter' in row_text:
                    for cell in row:
                        if cell and isinstance(cell, (int, float)):
                            if 2 <= cell <= 50:
                                data['size_nm'] = cell
                
                # PL peak
                if 'pl' in row_text or 'emission' in row_text:
                    for cell in row:
                        if cell and isinstance(cell, (int, float)):
                            if 350 <= cell <= 500:
                                data['PL_peak_nm'] = int(cell)
                
                # PLQY
                if 'plqy' in row_text or 'quantum yield' in row_text:
                    for cell in row:
                        if cell and isinstance(cell, (int, float)):
                            if 0 <= cell <= 100:
                                data['PLQY_percent'] = cell
                
                # FWHM
                if 'fwhm' in row_text or 'width' in row_text:
                    for cell in row:
                        if cell and isinstance(cell, (int, float)):
                            if 5 <= cell <= 100:
                                data['FWHM_nm'] = cell
        
        return data
    
    def extract_synthesis_conditions(self, text: str) -> Dict:
        """í•©ì„± ì¡°ê±´ ì¶”ì¶œ (ê°œì„ : ë¬¸ë§¥ ì¸ì‹)"""
        data = {}
        
        # CsPbCl3 í•©ì„± ì„¹ì…˜ë§Œ ì¶”ì¶œ ì‹œë„ (í™•ì¥: 5000ì)
        synthesis_section = ""
        
        # "CsPbCl3 synthesis" ë˜ëŠ” "QD synthesis" ì„¹ì…˜ ì°¾ê¸°
        synthesis_keywords = [
            r'synthesis\s+and\s+characterization',  # ê°€ì¥ êµ¬ì²´ì 
            r'cspbcl3.*?synthesis',
            r'quantum dot.*?synthesis',
            r'perovskite.*?synthesis',
            r'qd.*?preparation',
            r'experimental.*?section',
            r'methods.*?section',
        ]
        
        for keyword in synthesis_keywords:
            match = re.search(keyword, text, re.IGNORECASE | re.DOTALL)
            if match:
                # ë§¤ì¹˜ëœ ìœ„ì¹˜ë¶€í„° 5000ì ì¶”ì¶œ (ëŠ˜ë¦¼)
                start = match.start()
                synthesis_section = text[start:start+5000]
                logger.debug(f"âœ… í•©ì„± ì„¹ì…˜ ë°œê²¬: '{match.group()}'")
                break
        
        # ì„¹ì…˜ì„ ì°¾ì§€ ëª»í•˜ë©´ ì „ì²´ í…ìŠ¤íŠ¸ ì‚¬ìš©
        if not synthesis_section:
            synthesis_section = text
            logger.debug("âš ï¸ í•©ì„± ì„¹ì…˜ íŠ¹ì • ë¶ˆê°€ - ì „ì²´ í…ìŠ¤íŠ¸ ì‚¬ìš©")
        
        # ì˜¨ë„ ì¶”ì¶œ (ê°œì„ : hot injection ê·¼ì²˜ë§Œ + íŒ¨í„´ 3ë°° í™•ì¥)
        temp_patterns = [
            # Hot injection ëª…ì‹œ
            r'hot[- ]injection.*?(?:at|temperature|heated|to)\s*(\d{2,3})\s*[Â°Âº]?\s*C',
            r'hot[- ]inject(?:ed|ion).*?(\d{2,3})\s*[Â°Âº]?\s*C',
            r'(\d{2,3})\s*[Â°Âº]?\s*C.*?hot[- ]injection',
            
            # Temperature raised/increased
            r'temperature.*?(?:raised|increased|heated).*?(?:to|at)\s*(\d{2,3})\s*[Â°Âº]?\s*C',
            r'(?:raised|increased|heated).*?(?:to|at)\s*(\d{2,3})\s*[Â°Âº]?\s*C',
            r'(\d{2,3})\s*[Â°Âº]?\s*C.*?(?:raised|heated)',
            
            # Injection ì¼ë°˜
            r'inject(?:ed|ion).*?(?:at|temperature)\s*(\d{2,3})\s*[Â°Âº]?\s*C',
            r'temperature.*?(\d{2,3})\s*[Â°Âº]?\s*C.*?inject',
            r'(\d{2,3})\s*[Â°Âº]?\s*C.*?inject(?:ed|ion)',
            r'at\s*(\d{2,3})\s*[Â°Âº]?\s*C.*?(?:was|were)\s+inject',
            
            # Swift injection (ë³€í˜•)
            r'swift(?:ly)?.*?inject.*?(\d{2,3})\s*[Â°Âº]?\s*C',
            r'rapid(?:ly)?.*?inject.*?(\d{2,3})\s*[Â°Âº]?\s*C',
            
            # Cs precursor injection
            r'Cs[- ](?:oleate|precursor).*?inject.*?(\d{2,3})\s*[Â°Âº]?\s*C',
            r'inject.*?Cs[- ](?:oleate|precursor).*?(\d{2,3})\s*[Â°Âº]?\s*C',
            r'(\d{2,3})\s*[Â°Âº]?\s*C.*?Cs[- ](?:oleate|precursor).*?inject',
            
            # Synthesis temperature (ë¬¸ë§¥ í•„ìˆ˜)
            r'CsPbCl3.*?synthesized.*?(\d{2,3})\s*[Â°Âº]?\s*C',
            r'synthesized.*?CsPbCl3.*?(\d{2,3})\s*[Â°Âº]?\s*C',
            r'QDs.*?(?:formed|prepared|synthesized).*?(\d{2,3})\s*[Â°Âº]?\s*C',
            
            # Reaction temperature
            r'reaction temperature.*?(\d{2,3})\s*[Â°Âº]?\s*C',
            r'at\s*(\d{2,3})\s*[Â°Âº]?\s*C.*?(?:for|during).*?synthesis'
        ]
        
        for pattern in temp_patterns:
            match = re.search(pattern, synthesis_section, re.IGNORECASE)
            if match:
                temp = float(match.group(1))
                # í•©ë¦¬ì ì¸ ë²”ìœ„ ê²€ì¦
                if 100 <= temp <= 250:
                    data['injection_temp_C'] = temp
                    logger.debug(f"âœ… ì˜¨ë„ ì¶”ì¶œ: {temp}Â°C (íŒ¨í„´: hot-injection)")
                    break
        
        # Cs ì „êµ¬ì²´ (í™•ì¥: í™”í•™ì‹ + ì´ë¦„ + ì•½ì–´)
        cs_patterns = [
            (r'Cs2CO3', 'Cs2CO3'),
            (r'cesium\s+carbonate', 'Cs2CO3'),
            (r'CsOAc', 'CsOAc'),
            (r'Cs-OAc', 'CsOAc'),
            (r'cesium\s+acetate', 'CsOAc'),
            (r'Cs[- ]oleate', 'Cs-oleate'),
            (r'cesium\s+oleate', 'Cs-oleate'),
            (r'CsOA', 'Cs-oleate'),
            (r'Cs\s+precursor', 'Cs-precursor'),
        ]
        
        for pattern, source_name in cs_patterns:
            if re.search(pattern, synthesis_section, re.IGNORECASE):
                data['Cs_source'] = source_name
                logger.debug(f"âœ… Cs source: {source_name}")
                break
        
        # Pb ì „êµ¬ì²´ (í™•ì¥: í™”í•™ì‹ + ì´ë¦„ + ë³€í˜•)
        pb_patterns = [
            (r'PbCl2', 'PbCl2'),
            (r'PbClâ‚‚', 'PbCl2'),  # ì•„ë˜ì²¨ì
            (r'lead\s+chloride', 'PbCl2'),
            (r'lead\(II\)\s+chloride', 'PbCl2'),
            (r'lead\s*\(2\+\)\s+chloride', 'PbCl2'),
            (r'Pb[- ]chloride', 'PbCl2'),
        ]
        
        for pattern, source_name in pb_patterns:
            if re.search(pattern, synthesis_section, re.IGNORECASE):
                data['Pb_source'] = source_name
                logger.debug(f"âœ… Pb source: {source_name}")
                break
        
        # Cl ì „êµ¬ì²´
        data['Cl_source'] = data.get('Pb_source', 'PbCl2')
        
        # ì–‘ ì¶”ì¶œ (mmol) - CsPbCl3 í•©ì„± ì„¹ì…˜ì—ì„œë§Œ
        amount_patterns = [
            r'(\d+\.?\d*)\s*mmol.*?(?:PbCl2|lead chloride)',
            r'PbCl2.*?(\d+\.?\d*)\s*mmol',
        ]
        
        for pattern in amount_patterns:
            match = re.search(pattern, synthesis_section, re.IGNORECASE)
            if match:
                amount = float(match.group(1))
                if 0.01 <= amount <= 10:  # í•©ë¦¬ì ì¸ ë²”ìœ„
                    data['Pb_amount_mmol'] = amount
                    break
        
        # ë¦¬ê°„ë“œ ì¶”ì¶œ (OA, OLA, ODE)
        ligand_patterns = {
            'OA_volume_ml': [r'oleic acid.*?(\d+\.?\d*)\s*(?:ml|mL|Î¼L)', 
                            r'OA.*?(\d+\.?\d*)\s*(?:ml|mL|Î¼L)'],
            'OLA_volume_ml': [r'oleylamine.*?(\d+\.?\d*)\s*(?:ml|mL|Î¼L)',
                             r'OLA.*?(\d+\.?\d*)\s*(?:ml|mL|Î¼L)'],
            'ODE_volume_ml': [r'octadecene.*?(\d+\.?\d*)\s*(?:ml|mL|Î¼L)',
                             r'ODE.*?(\d+\.?\d*)\s*(?:ml|mL|Î¼L)']
        }
        
        for key, patterns in ligand_patterns.items():
            for pattern in patterns:
                match = re.search(pattern, text, re.IGNORECASE)
                if match:
                    volume = float(match.group(1))
                    # Î¼L -> mL ë³€í™˜
                    if 'Î¼L' in match.group(0) or 'uL' in match.group(0):
                        volume = volume / 1000
                    data[key] = volume
                    break
        
        # ë°˜ì‘ ì‹œê°„ (min)
        time_patterns = [
            r'(\d+\.?\d*)\s*min',
            r'(\d+\.?\d*)\s*minutes',
            r'(\d+\.?\d*)\s*h(?:our)?'  # ì‹œê°„ë„ ì¶”ì¶œ
        ]
        
        for pattern in time_patterns:
            match = re.search(pattern, text, re.IGNORECASE)
            if match:
                time_val = float(match.group(1))
                if 'h' in pattern:
                    time_val *= 60  # ì‹œê°„ -> ë¶„
                data['reaction_time_min'] = time_val
                break
        
        # í•©ì„± ë°©ë²• ì¶”ì¶œ
        method_keywords = {
            'hot-injection': ['hot injection', 'hot-injection', 'injection method'],
            'room-temperature': ['room temperature', 'RT synthesis', 'ambient'],
            'microwave': ['microwave', 'MW synthesis'],
            'sonication': ['sonication', 'ultrasonic', 'sonochemical']
        }
        
        for method, keywords in method_keywords.items():
            for keyword in keywords:
                if re.search(keyword, text, re.IGNORECASE):
                    data['synthesis_method'] = method
                    break
            if 'synthesis_method' in data:
                break
        
        return data
    
    def extract_qd_properties(self, text: str) -> Dict:
        """QD íŠ¹ì„± ì¶”ì¶œ"""
        data = {}
        
        # í¬ê¸° (nm)
        size_patterns = [
            r'size.*?(\d+\.?\d*)\s*nm',
            r'diameter.*?(\d+\.?\d*)\s*nm',
            r'(\d+\.?\d*)\s*nm.*?(?:size|diameter|particle)'
        ]
        
        for pattern in size_patterns:
            match = re.search(pattern, text, re.IGNORECASE)
            if match:
                data['size_nm'] = float(match.group(1))
                break
        
        # PL peak (nm)
        pl_patterns = [
            r'PL.*?(\d{3})\s*nm',
            r'emission.*?(\d{3})\s*nm',
            r'photoluminescence.*?(\d{3})\s*nm'
        ]
        
        for pattern in pl_patterns:
            match = re.search(pattern, text, re.IGNORECASE)
            if match:
                wavelength = int(match.group(1))
                if 350 <= wavelength <= 500:  # CsPbCl3 ë²”ìœ„
                    data['PL_peak_nm'] = wavelength
                    break
        
        # PLQY (%)
        plqy_patterns = [
            r'PLQY.*?(\d+\.?\d*)\s*%',
            r'quantum yield.*?(\d+\.?\d*)\s*%',
            r'QY.*?(\d+\.?\d*)\s*%'
        ]
        
        for pattern in plqy_patterns:
            match = re.search(pattern, text, re.IGNORECASE)
            if match:
                qy = float(match.group(1))
                if 0 <= qy <= 100:
                    data['PLQY_percent'] = qy
                    break
        
        # FWHM (nm)
        fwhm_patterns = [
            r'FWHM.*?(\d+\.?\d*)\s*nm',
            r'full width.*?(\d+\.?\d*)\s*nm'
        ]
        
        for pattern in fwhm_patterns:
            match = re.search(pattern, text, re.IGNORECASE)
            if match:
                data['FWHM_nm'] = float(match.group(1))
                break
        
        # Absorption peak (nm)
        abs_patterns = [
            r'absorption.*?(\d{3})\s*nm',
            r'absorbance.*?(\d{3})\s*nm',
            r'1S.*?(\d{3})\s*nm'
        ]
        
        for pattern in abs_patterns:
            match = re.search(pattern, text, re.IGNORECASE)
            if match:
                wavelength = int(match.group(1))
                if 300 <= wavelength <= 450:
                    data['abs_1S_peak_nm'] = wavelength
                    break
        
        return data
    
    def extract_metadata(self, doi: str, text: str) -> Dict:
        """ë©”íƒ€ë°ì´í„° ì¶”ì¶œ (CrossRef API ì‚¬ìš©)"""
        try:
            url = f"https://api.crossref.org/works/{doi}"
            response = requests.get(url, timeout=10)
            
            if response.status_code == 200:
                data = response.json()['message']
                
                authors = data.get('author', [])
                author_names = [f"{a.get('given', '')} {a.get('family', '')}" 
                               for a in authors[:3]]  # ì²˜ìŒ 3ëª…ë§Œ
                
                return {
                    'year': data.get('published', {}).get('date-parts', [[0]])[0][0],
                    'authors': ', '.join(author_names),
                    'journal': data.get('container-title', ['Unknown'])[0][:50]
                }
        except Exception as e:
            logger.error(f"âŒ ë©”íƒ€ë°ì´í„° ì¶”ì¶œ ì‹¤íŒ¨: {e}")
        
        return {
            'year': 2024,
            'authors': 'Unknown',
            'journal': 'Unknown'
        }
    
    def extract_all_data(self, doi: str, paper_id: str) -> Dict:
        """ë…¼ë¬¸ì—ì„œ ëª¨ë“  ë°ì´í„° ì¶”ì¶œ (ì „ì²´ íŒŒì´í”„ë¼ì¸ - ê°œì„ : í‘œ ìš°ì„ )"""
        logger.info(f"ğŸ”¬ ë°ì´í„° ì¶”ì¶œ ì‹œì‘: {doi}")
        
        # 1. PDF ë‹¤ìš´ë¡œë“œ ì‹œë„
        pdf_path = self.download_pdf(doi)
        
        if not pdf_path:
            logger.warning(f"âš ï¸  PDF ì—†ìŒ, ë©”íƒ€ë°ì´í„°ë§Œ ì €ì¥: {doi}")
            metadata = self.extract_metadata(doi, "")
            return {
                'paper_id': paper_id,
                'doi': doi,
                **metadata,
                'notes': 'PDF not available - metadata only'
            }
        
        # 2. í…ìŠ¤íŠ¸ ì¶”ì¶œ
        text = self.extract_text_from_pdf(pdf_path)
        
        if not text:
            logger.warning(f"âš ï¸  í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨: {doi}")
            return None
        
        # 3. í‘œ ì¶”ì¶œ (ìƒˆë¡œìš´ ê¸°ëŠ¥ - ìš°ì„ ìˆœìœ„ 1)
        logger.info("ğŸ“Š í‘œ ì¶”ì¶œ ì‹œë„...")
        tables = self.extract_tables_from_pdf(pdf_path)
        
        table_synthesis = {}
        table_properties = {}
        
        if tables:
            table_synthesis = self.parse_synthesis_from_table(tables)
            table_properties = self.parse_properties_from_table(tables)
            
            if table_synthesis:
                logger.info(f"   âœ… í‘œì—ì„œ í•©ì„± ì¡°ê±´ {len(table_synthesis)}ê°œ ì¶”ì¶œ")
            if table_properties:
                logger.info(f"   âœ… í‘œì—ì„œ QD íŠ¹ì„± {len(table_properties)}ê°œ ì¶”ì¶œ")
        
        # 4. í…ìŠ¤íŠ¸ì—ì„œ ì¶”ì¶œ (í‘œì—ì„œ ëª» ì°¾ì€ ê²ƒë§Œ)
        logger.info("ğŸ“ í…ìŠ¤íŠ¸ì—ì„œ ì¶”ì¶œ...")
        metadata = self.extract_metadata(doi, text)
        text_synthesis = self.extract_synthesis_conditions(text)
        text_properties = self.extract_qd_properties(text)
        
        # 5. í†µí•© (í‘œ ë°ì´í„° ìš°ì„ , í…ìŠ¤íŠ¸ë¡œ ë³´ì™„)
        synthesis = {**text_synthesis, **table_synthesis}  # í‘œê°€ í…ìŠ¤íŠ¸ë¥¼ ë®ì–´ì”€
        properties = {**text_properties, **table_properties}
        
        result = {
            'paper_id': paper_id,
            'doi': doi,
            **metadata,
            **synthesis,
            **properties
        }
        
        # 6. ì¶”ì¶œëœ í•„ë“œ ë¡œê¹…
        extracted_fields = [k for k, v in result.items() 
                           if v is not None and k not in ['paper_id', 'doi', 'year', 'authors', 'journal']]
        
        if extracted_fields:
            logger.info(f"âœ… ì¶”ì¶œ ì™„ë£Œ: {len(extracted_fields)}ê°œ í•„ë“œ")
            logger.info(f"   í•©ì„±: {[f for f in extracted_fields if f in ['injection_temp_C', 'Pb_amount_mmol', 'OA_volume_ml', 'OLA_volume_ml', 'ODE_volume_ml']]}")
            logger.info(f"   íŠ¹ì„±: {[f for f in extracted_fields if f in ['size_nm', 'PL_peak_nm', 'PLQY_percent', 'FWHM_nm']]}")
        else:
            logger.warning("âš ï¸ ë°ì´í„° í•„ë“œ ì¶”ì¶œ ì—†ìŒ")
        
        return result


def test_extractor():
    """ì¶”ì¶œê¸° í…ŒìŠ¤íŠ¸"""
    extractor = PDFDataExtractor(Path("pdf/downloaded"))
    
    # í…ŒìŠ¤íŠ¸ DOI (ì˜¤í”ˆì•¡ì„¸ìŠ¤)
    test_doi = "10.1038/srep45906"
    
    result = extractor.extract_all_data(test_doi, "TEST001")
    
    print("\n" + "="*80)
    print("ğŸ“Š ì¶”ì¶œ ê²°ê³¼:")
    print("="*80)
    for key, value in result.items():
        if value is not None:
            print(f"  {key}: {value}")
    print("="*80)


if __name__ == "__main__":
    logging.basicConfig(level=logging.INFO)
    test_extractor()
