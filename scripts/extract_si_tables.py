#!/usr/bin/env python3
"""
Supplementary Informationì—ì„œ í‘œ ìë™ ì¶”ì¶œ
tabula-py ì‚¬ìš©í•˜ì—¬ PDF í‘œ â†’ pandas DataFrame
"""

import sys
from pathlib import Path
import pandas as pd
import logging
import tabula

# í”„ë¡œì íŠ¸ ê²½ë¡œ
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


def extract_tables_from_pdf(pdf_path: Path) -> list:
    """PDFì—ì„œ ëª¨ë“  í‘œ ì¶”ì¶œ"""
    
    logger.info(f"ğŸ“„ PDF ì²˜ë¦¬ ì¤‘: {pdf_path.name}")
    
    try:
        # ëª¨ë“  í˜ì´ì§€ì—ì„œ í‘œ ì¶”ì¶œ
        tables = tabula.read_pdf(
            str(pdf_path),
            pages='all',
            multiple_tables=True,
            lattice=True,  # ê²©ìì„ ì´ ìˆëŠ” í‘œ
            stream=True    # ê²©ìì„  ì—†ëŠ” í‘œë„ ì‹œë„
        )
        
        logger.info(f"âœ… {len(tables)}ê°œ í‘œ ë°œê²¬")
        
        return tables
        
    except Exception as e:
        logger.error(f"âŒ í‘œ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
        return []


def identify_data_table(df: pd.DataFrame) -> bool:
    """ë°ì´í„° í‘œì¸ì§€ íŒë‹¨"""
    
    # CsPbCl3 ê´€ë ¨ í‚¤ì›Œë“œ
    keywords = ['temp', 'pbcl2', 'cs', 'oleate', 'oa', 'ola', 'ode', 
                'size', 'pl', 'plqy', 'fwhm', 'injection']
    
    # ì»¬ëŸ¼ëª…ì— í‚¤ì›Œë“œê°€ ìˆëŠ”ì§€ í™•ì¸
    columns_str = ' '.join([str(c).lower() for c in df.columns])
    
    matches = sum(1 for kw in keywords if kw in columns_str)
    
    return matches >= 3  # 3ê°œ ì´ìƒ í‚¤ì›Œë“œ ë§¤ì¹˜


def clean_and_standardize(df: pd.DataFrame) -> pd.DataFrame:
    """í‘œ ë°ì´í„° ì •ë¦¬ ë° í‘œì¤€í™”"""
    
    # ì»¬ëŸ¼ëª… ì •ë¦¬
    df.columns = [str(c).strip().lower().replace(' ', '_') for c in df.columns]
    
    # ë¹ˆ í–‰ ì œê±°
    df = df.dropna(how='all')
    
    # ìˆ«ì ì»¬ëŸ¼ ë³€í™˜
    for col in df.columns:
        if any(kw in col for kw in ['temp', 'mmol', 'ml', 'size', 'nm', 'plqy', 'fwhm']):
            df[col] = pd.to_numeric(df[col], errors='coerce')
    
    return df


def main():
    """ë©”ì¸ ì‹¤í–‰"""
    
    print("\n" + "="*80)
    print("ğŸ“Š Supplementary Information í‘œ ì¶”ì¶œ")
    print("="*80)
    
    # SI ë””ë ‰í† ë¦¬
    si_dir = project_root / "pdf" / "supplementary"
    
    # PDF íŒŒì¼ ì°¾ê¸°
    si_files = list(si_dir.glob("*.pdf"))
    
    if not si_files:
        logger.error("âŒ Supplementary Information PDF ì—†ìŒ")
        logger.info("\nğŸ’¡ ë‹¤ìš´ë¡œë“œ ê°€ì´ë“œ:")
        logger.info("   docs/SUPPLEMENTARY_INFO_DOWNLOAD_GUIDE.md ì°¸ì¡°")
        return
    
    logger.info(f"âœ… {len(si_files)}ê°œ PDF íŒŒì¼ ë°œê²¬\n")
    
    all_data_tables = []
    
    # ê° PDF ì²˜ë¦¬
    for pdf_path in si_files:
        logger.info("="*80)
        logger.info(f"ğŸ“„ {pdf_path.name}")
        logger.info("="*80)
        
        # í‘œ ì¶”ì¶œ
        tables = extract_tables_from_pdf(pdf_path)
        
        # ê° í‘œ ë¶„ì„
        for i, table in enumerate(tables, 1):
            logger.info(f"\ní‘œ {i}:")
            logger.info(f"  í¬ê¸°: {table.shape[0]} í–‰ x {table.shape[1]} ì—´")
            logger.info(f"  ì»¬ëŸ¼: {list(table.columns)[:5]}...")
            
            # ë°ì´í„° í‘œì¸ì§€ í™•ì¸
            if identify_data_table(table):
                logger.info(f"  âœ… CsPbCl3 ë°ì´í„° í‘œë¡œ ì‹ë³„!")
                
                # ì •ë¦¬ ë° í‘œì¤€í™”
                clean_table = clean_and_standardize(table)
                all_data_tables.append({
                    'source': pdf_path.name,
                    'table_num': i,
                    'data': clean_table
                })
            else:
                logger.info(f"  âš ï¸  ê´€ë ¨ ë°ì´í„° ì•„ë‹˜")
    
    # ê²°ê³¼ ì €ì¥
    if all_data_tables:
        logger.info("\n" + "="*80)
        logger.info(f"ğŸ’¾ ë°ì´í„° ì €ì¥")
        logger.info("="*80)
        
        for item in all_data_tables:
            output_name = f"reference_data_table{item['table_num']}.csv"
            output_path = project_root / "data" / output_name
            
            item['data'].to_csv(output_path, index=False)
            
            logger.info(f"âœ… {output_name}")
            logger.info(f"   ìƒ˜í”Œ ìˆ˜: {len(item['data'])}")
            logger.info(f"   ì»¬ëŸ¼ ìˆ˜: {len(item['data'].columns)}")
        
        # ì „ì²´ í†µí•©
        combined = pd.concat([item['data'] for item in all_data_tables], 
                            ignore_index=True)
        
        combined_path = project_root / "data" / "reference_dataset_extracted.csv"
        combined.to_csv(combined_path, index=False)
        
        logger.info(f"\nâœ… í†µí•© ë°ì´í„°: {combined_path.name}")
        logger.info(f"   ì´ ìƒ˜í”Œ: {len(combined)}")
        logger.info(f"   ì´ ì»¬ëŸ¼: {len(combined.columns)}")
        
        print("\n" + "="*80)
        print("ğŸ‰ ë°ì´í„° ì¶”ì¶œ ì™„ë£Œ!")
        print("="*80)
        print(f"ğŸ“Š ì´ {len(combined)}ê°œ ìƒ˜í”Œ í™•ë³´")
        print(f"ğŸ“ ì €ì¥ ìœ„ì¹˜: data/reference_dataset_extracted.csv")
        print(f"\nğŸš€ ë‹¤ìŒ ë‹¨ê³„: ML ëª¨ë¸ í•™ìŠµ ì‹œì‘!")
        print("="*80 + "\n")
        
    else:
        logger.warning("\nâš ï¸  ë°ì´í„° í‘œë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤")
        logger.info("\nğŸ’¡ ëŒ€ì•ˆ:")
        logger.info("   1. Excel íŒŒì¼(.xlsx)ë¡œ ë‹¤ìš´ë¡œë“œ ì‹œë„")
        logger.info("   2. ë…¼ë¬¸ ë³¸ë¬¸ í‘œì—ì„œ ìˆ˜ë™ ì¶”ì¶œ")
        logger.info("   3. ì €ìì—ê²Œ ë°ì´í„° ìš”ì²­")


if __name__ == "__main__":
    main()
